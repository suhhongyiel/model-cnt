# -*- coding: utf-8 -*-
"""
activity_sleep_llm_pipeline.py (v3)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CSV(í™œë™+ìˆ˜ë©´) â†’ CatBoost íšŒê·€ + SHAP â†’ Llama-3 8B GGUF í•œêµ­ì–´ ì½”ì¹­

ğŸƒ 2025-06-04 UPDATE: LLM ì…ë ¥ì„ **ìµœê·¼ Nì¼(ê¸°ë³¸ 7ì¼)** ë¡œ ì¶•ì†Œí•´
í† í° ì´ˆê³¼ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤. CatBoost í•™ìŠµê³¼ SHAP ê³„ì‚°ì€ ì „ì²´ ë°ì´í„°ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.

ì„¤ì¹˜
-----
    pip install pandas catboost shap llama-cpp-python

CLI ì˜ˆì‹œ
--------
    python activity_sleep_llm_pipeline.py data.csv --model llama.gguf --window 7
"""

import argparse
from pathlib import Path
import textwrap
from typing import List, Dict

import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
import shap
from llama_cpp import Llama

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. CSV ë¡œë“œ & ì „ì²˜ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_data(csv_path: Path) -> pd.DataFrame:
    df = pd.read_csv(csv_path)
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"])
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. CatBoost + SHAP
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_feature_matrix(df: pd.DataFrame, target: str) -> pd.DataFrame:
    """íƒ€ê¹ƒ ì œì™¸ + ìˆ«ìí˜• ì—´ë§Œ ë°˜í™˜"""
    return df.drop(columns=[target]).select_dtypes(include="number")


def train_model(df: pd.DataFrame, target: str = "efficiency") -> CatBoostRegressor:
    X = get_feature_matrix(df, target)
    y = df[target]
    model = CatBoostRegressor(
        iterations=500,
        depth=6,
        learning_rate=0.05,
        loss_function="RMSE",
        silent=True,
    )
    model.fit(X, y)
    return model


def make_shap_summary(model: CatBoostRegressor, X: pd.DataFrame, top_k: int = 5) -> List[Dict]:
    """ì „ì²´ Xë¡œ SHAP ê³„ì‚° í›„ ë§ˆì§€ë§‰ ìƒ˜í”Œ ê¸°ì¤€ ìƒìœ„ í”¼ì²˜ ë°˜í™˜"""
    explainer = shap.TreeExplainer(model)
    shap_vals = explainer.shap_values(X)
    last_vals = shap_vals[-1]
    idx = np.abs(last_vals).argsort()[::-1][:top_k]
    return [
        {
            "feature": X.columns[i],
            "impact": float(last_vals[i]),
            "value": float(X.iloc[-1, i]),
        }
        for i in idx
    ]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. LLM í”„ë¡¬í”„íŠ¸ & í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = textwrap.dedent(
    """
    ë‹¹ì‹ ì€ ì „ë¬¸ ìˆ˜ë©´Â·í™œë™ ì½”ì¹˜ì´ì ìƒì²´ì‹ í˜¸ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.

    ğŸ”´ **ì ˆëŒ€ ê·œì¹™** ğŸ”´
    1. ì˜¤ì§ í•œêµ­ì–´ë§Œ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ì˜ì–´Â·ìˆ«ì í˜¼í•© í‘œê¸°, ë¡œë§ˆì, ì´ëª¨í‹°ì½˜ ëª¨ë‘ ê¸ˆì§€.
    2. ì¶œë ¥ í˜•ì‹ ì˜ ì–‘ì‹ì„ ë”°ë¼ì„œ ì§„í–‰ í•´ì£¼ì„¸ìš”.

    [ì¶œë ¥ í˜•ì‹]
    [advice] ìˆ˜ë©´ì˜ ì§ˆì„ ë†’ì´ê¸° ìœ„í•œ í•µì‹¬ ì‹¤ì²œ ì¡°ì–¸ êµ¬ì œì ìœ¼ë¡œ ì œì‹œ 2~3ë¬¸ì¥
    [why] ì„œë¡œ ë‹¤ë¥¸ ì§€í‘œë¥¼ ìµœì†Œ 3ê°œ ì´ìƒ, ì‹¤ì œ ìˆ«ìë¥¼ í¬í•¨í•´ ê°œì„  ì‚¬í•­ì„ ìœ„í•œ ìˆ˜ì¹˜ì  ê·¼ê±° ì„¤ëª… 2ë¬¸ì¥
    [ask] ì¶”ê°€ë¡œ í™•ì¸í•˜ê³  ì‹¶ì€ ì§ˆë¬¸ 1ë¬¸ì¥
    """
)

USER_PROMPT_TEMPLATE = textwrap.dedent(
    """
    ### ìµœê·¼ {n_days}ì¼ ì›ë³¸ ë°ì´í„°
    ```
    {table}
    ```

    ### ë¶„ì„ ìš”ì•½ (ì „ì²´ ë°ì´í„° ê¸°ë°˜)
    - CatBoost ì˜ˆì¸¡ ìˆ˜ë©´ íš¨ìœ¨: {pred:.1f}%
    - SHAP ì˜í–¥ ìƒìœ„ {k}ê°œ í”¼ì²˜:
    {shap_lines}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¡°ì–¸ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    """
)


def build_user_prompt(df_last: pd.DataFrame, pred: float, shap_top: List[Dict]) -> str:
    table = df_last.to_string(index=False)
    shap_lines = "\n".join(
        f"  * {d['feature']}: ê°’ {d['value']:.2f}, ì˜í–¥ {d['impact']:+.2f}" for d in shap_top
    )
    return USER_PROMPT_TEMPLATE.format(
        n_days=len(df_last),
        table=table,
        pred=pred,
        k=len(shap_top),
        shap_lines=shap_lines,
    )


def run_llm(model_path: Path, system_prompt: str, user_prompt: str, n_threads: int = 8) -> str:
    llm = Llama(
        model_path=str(model_path),
        n_threads=n_threads,
        n_ctx=4096,
        temperature=0.5,
    )
    result = llm.create_chat_completion(
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        stop=["[ask]"]
    )
    return result["choices"][0]["message"]["content"].strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ë©”ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main(csv: Path, model_path: Path, window: int):
    df = load_data(csv)

    # â”€â”€ 2-1) CatBoost í•™ìŠµ & ì˜ˆì¸¡ (ì „ì²´ ë°ì´í„° ì‚¬ìš©)
    model = train_model(df, target="efficiency")
    X_full = get_feature_matrix(df, "efficiency")
    pred_eff = float(model.predict(X_full.iloc[[-1]])[0])
    shap_top = make_shap_summary(model, X_full)

    # â”€â”€ 2-2) LLM ì—ëŠ” ìµœê·¼ window ì¼ë§Œ ì „ë‹¬
    df_last = df.tail(window)

    user_prompt = build_user_prompt(df_last, pred_eff, shap_top)
    advice = run_llm(model_path, SYSTEM_PROMPT, user_prompt)

    print("\n=== LLM í•œêµ­ì–´ ì½”ì¹­ ë©”ì‹œì§€ ===\n")
    print(advice)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="í™œë™+ìˆ˜ë©´ CSV â†’ CatBoost+LLM ì½”ì¹­")
    parser.add_argument("--csv", type=Path, help="CSV íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model", type=Path, required=True, help="GGUF ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument("--window", type=int, default=7, help="LLM ì…ë ¥ì— ì‚¬ìš©í•  ìµœê·¼ ì¼ìˆ˜ (ê¸°ë³¸ 7)")
    args = parser.parse_args()

    main(args.csv, args.model, args.window)
